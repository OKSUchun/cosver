"""
ë¹„ìŠ·í•œ êµ¬ë„ì˜ ì‚¬ì§„ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì´ë¯¸ì§€ì˜ êµ¬ë„(composition)ë¥¼ ë¶„ì„í•˜ì—¬ ìœ ì‚¬í•œ êµ¬ë„ì˜ ì´ë¯¸ì§€ë“¤ì„ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
êµ¬ë„ íŠ¹ì§•: ì—£ì§€ ë¶„í¬, ê³µê°„ì  ë ˆì´ì•„ì›ƒ, ìƒ‰ìƒ ë¶„í¬, OCR í…ìŠ¤íŠ¸ ë“±ì„ ê³ ë ¤í•©ë‹ˆë‹¤.
"""
import shutil
import re
from pathlib import Path
import numpy as np
from PIL import Image
import cv2
from sklearn.cluster import DBSCAN, KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from collections import defaultdict

# í‰ê°€ ëª¨ë“ˆ import (ì„ íƒì )
try:
    from tests.evaluate_clustering import (
        convert_cluster_result_to_list,
        evaluate_clustering,
        print_evaluation_report,
        generate_ground_truth_template,
    )
    EVALUATION_AVAILABLE = True
except ImportError:
    EVALUATION_AVAILABLE = False
    print("âš ï¸  í‰ê°€ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‰ê°€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ tests/evaluate_clustering.pyê°€ í•„ìš”í•©ë‹ˆë‹¤.")

# OCR ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì„ íƒì )
try:
    import easyocr
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("âš ï¸  easyocrì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install easyocr'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# ì´ë¯¸ì§€ í•´ì‹œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì„ íƒì )
try:
    import imagehash
    IMAGEHASH_AVAILABLE = True
except ImportError:
    IMAGEHASH_AVAILABLE = False
    print("âš ï¸  imagehashê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í•´ì‹œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install imagehash'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")


def load_image(image_path: Path) -> np.ndarray:
    """ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  numpy ë°°ì—´ë¡œ ë³€í™˜"""
    try:
        img = Image.open(image_path)
        # RGBë¡œ ë³€í™˜ (RGBAë‚˜ ë‹¤ë¥¸ í˜•ì‹ ì²˜ë¦¬)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        return np.array(img)
    except Exception as e:
        print(f"âš ï¸  ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {image_path.name}: {e}")
        return None


def preprocess_image_for_ocr(image: np.ndarray) -> np.ndarray:
    """OCR ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ë„ˆë¬´ ì‘ìœ¼ë©´ í™•ëŒ€)
    h, w = gray.shape
    if h < 300 or w < 300:
        scale = max(300 / h, 300 / w)
        new_h, new_w = int(h * scale), int(w * scale)
        gray = cv2.resize(gray, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
    
    # ëŒ€ë¹„ í–¥ìƒ (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    gray = cv2.GaussianBlur(gray, (3, 3), 0)
    
    # ì´ì§„í™” (Otsu's method)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    return binary


def correct_ocr_typos(text: str) -> str:
    """OCR ì˜¤íƒ€ë¥¼ ë³´ì •í•©ë‹ˆë‹¤ (ì˜ˆ: "3oml" -> "30ml", "5oml" -> "50ml")"""
    # ì¼ë°˜ì ì¸ OCR ì˜¤íƒ€ íŒ¨í„´ ë³´ì •
    corrections = {
        r'(\d+)o\s*ml': r'\g<1>0ml',  # "3oml" -> "30ml", "5oml" -> "50ml"
        r'(\d+)o\s*ML': r'\g<1>0ml',
        r'(\d+)O\s*ml': r'\g<1>0ml',
        r'(\d+)O\s*ML': r'\g<1>0ml',
    }
    
    corrected_text = text
    for pattern, replacement in corrections.items():
        corrected_text = re.sub(pattern, replacement, corrected_text, flags=re.IGNORECASE)
    
    return corrected_text


def extract_text_from_image(image: np.ndarray, reader=None) -> dict:
    """
    ì´ë¯¸ì§€ì—ì„œ OCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ìˆ«ì, ë‹¨ìœ„ ë“±)
    """
    if not OCR_AVAILABLE or reader is None:
        return {
            "has_text": 0.0,
            "volume_ml": 0.0,  # ml ë‹¨ìœ„ ìˆ«ì
            "has_ml": 0.0,  # ml í…ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€
            "numbers": [],  # ë°œê²¬ëœ ëª¨ë“  ìˆ«ì
        }
    
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image = preprocess_image_for_ocr(image)
        
        # OCR ìˆ˜í–‰
        results = reader.readtext(processed_image)
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
        all_text = " ".join([result[1] for result in results]).lower()
        
        # OCR ì˜¤íƒ€ ë³´ì •
        corrected_text = correct_ocr_typos(all_text)
        
        # ml ë‹¨ìœ„ ì°¾ê¸° (ì˜ˆ: "30ml", "50ml", "30 ml", "50 ml")
        ml_pattern = r'(\d+)\s*ml'
        ml_matches = re.findall(ml_pattern, corrected_text)
        
        volume_ml = 0.0
        if ml_matches:
            # ê°€ì¥ í° ìˆ«ìë¥¼ ì„ íƒ (ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš°)
            volume_ml = float(max([int(m) for m in ml_matches], key=int))
        
        # ëª¨ë“  ìˆ«ì ì°¾ê¸°
        number_pattern = r'\d+'
        numbers = [int(n) for n in re.findall(number_pattern, corrected_text)]
        
        return {
            "has_text": 1.0 if corrected_text.strip() else 0.0,
            "volume_ml": volume_ml,
            "has_ml": 1.0 if ml_matches else 0.0,
            "numbers": numbers,
            "text": corrected_text,  # ë””ë²„ê¹…ìš©
            "original_text": all_text,  # ì›ë³¸ í…ìŠ¤íŠ¸
        }
    except Exception as e:
        print(f"âš ï¸  OCR ì˜¤ë¥˜: {e}")
        return {
            "has_text": 0.0,
            "volume_ml": 0.0,
            "has_ml": 0.0,
            "numbers": [],
        }


def extract_image_hash(image: np.ndarray) -> np.ndarray:
    """ì´ë¯¸ì§€ í•´ì‹œ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤ (perceptual hashing)"""
    if not IMAGEHASH_AVAILABLE:
        return np.zeros(64)  # í•´ì‹œê°€ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€ (8x8 = 64)
    
    try:
        pil_image = Image.fromarray(image)
        # dHash (difference hash) ì‚¬ìš©
        hash_value = imagehash.dhash(pil_image, hash_size=8)
        # í•´ì‹œë¥¼ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜ (8x8 = 64ë¹„íŠ¸)
        hash_str = str(hash_value)
        # 16ì§„ìˆ˜ ë¬¸ìì—´ì„ 64ë¹„íŠ¸ ë°°ì—´ë¡œ ë³€í™˜
        hash_int = int(hash_str, 16)
        hash_array = np.array([(hash_int >> i) & 1 for i in range(64)], dtype=float)
        return hash_array
    except Exception:
        return np.zeros(64)


def extract_composition_features(image: np.ndarray, ocr_features: dict = None) -> np.ndarray:
    """
    ì´ë¯¸ì§€ì˜ êµ¬ë„ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    íŠ¹ì§•:
    1. ì—£ì§€ ë¶„í¬ (9ê°œ ì˜ì—­ìœ¼ë¡œ ë‚˜ëˆˆ ì—£ì§€ ë°€ë„)
    2. ìƒ‰ìƒ ë¶„í¬ (9ê°œ ì˜ì—­ì˜ í‰ê·  ìƒ‰ìƒ)
    3. ì „ì²´ ì—£ì§€ íˆìŠ¤í† ê·¸ë¨
    4. ê³µê°„ì  ë ˆì´ì•„ì›ƒ (ì¤‘ì‹¬, ëŒ€ì¹­ì„± ë“±)
    """
    if image is None:
        return None
    
    h, w = image.shape[:2]
    features = []
    
    # 1. ì—£ì§€ ê²€ì¶œ
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    edges = cv2.Canny(gray, 50, 150)
    
    # 2. 3x3 ê·¸ë¦¬ë“œë¡œ ì´ë¯¸ì§€ë¥¼ ë‚˜ëˆ ì„œ ê° ì˜ì—­ì˜ íŠ¹ì§• ì¶”ì¶œ
    grid_size = 3
    cell_h, cell_w = h // grid_size, w // grid_size
    
    for i in range(grid_size):
        for j in range(grid_size):
            y1, y2 = i * cell_h, (i + 1) * cell_h
            x1, x2 = j * cell_w, (j + 1) * cell_w
            
            # ì—£ì§€ ë°€ë„
            cell_edges = edges[y1:y2, x1:x2]
            edge_density = np.sum(cell_edges > 0) / (cell_h * cell_w)
            features.append(edge_density)
            
            # í‰ê·  ìƒ‰ìƒ (RGB)
            cell_image = image[y1:y2, x1:x2]
            avg_color = np.mean(cell_image, axis=(0, 1))
            features.extend(avg_color)
    
    # 3. ì „ì²´ ì—£ì§€ íˆìŠ¤í† ê·¸ë¨ (8ê°œ bin)
    edge_hist = np.histogram(edges[edges > 0], bins=8, range=(0, 255))[0]
    edge_hist = edge_hist / (np.sum(edge_hist) + 1e-6)  # ì •ê·œí™”
    features.extend(edge_hist)
    
    # 4. ì¤‘ì‹¬ ì˜ì—­ì˜ íŠ¹ì§• (ì¤‘ì•™ 1/3 ì˜ì—­)
    center_y1, center_y2 = h // 3, 2 * h // 3
    center_x1, center_x2 = w // 3, 2 * w // 3
    center_region = image[center_y1:center_y2, center_x1:center_x2]
    center_avg_color = np.mean(center_region, axis=(0, 1))
    features.extend(center_avg_color)
    
    # 5. ìˆ˜í‰/ìˆ˜ì§ ëŒ€ì¹­ì„± ì ìˆ˜
    # ìˆ˜í‰ ëŒ€ì¹­ì„±: ìƒë‹¨ê³¼ í•˜ë‹¨ì˜ ìœ ì‚¬ë„
    top_half = gray[:h//2, :]
    bottom_half = cv2.flip(gray[h//2:, :], 0)
    if top_half.shape == bottom_half.shape:
        horizontal_symmetry = 1.0 - np.mean(np.abs(top_half.astype(float) - bottom_half.astype(float))) / 255.0
    else:
        horizontal_symmetry = 0.0
    
    # ìˆ˜ì§ ëŒ€ì¹­ì„±: ì¢Œì¸¡ê³¼ ìš°ì¸¡ì˜ ìœ ì‚¬ë„
    left_half = gray[:, :w//2]
    right_half = cv2.flip(gray[:, w//2:], 1)
    if left_half.shape == right_half.shape:
        vertical_symmetry = 1.0 - np.mean(np.abs(left_half.astype(float) - right_half.astype(float))) / 255.0
    else:
        vertical_symmetry = 0.0
    
    features.extend([horizontal_symmetry, vertical_symmetry])
    
    # 6. OCR íŠ¹ì§• ì¶”ê°€ (í…ìŠ¤íŠ¸ ì •ë³´)
    if ocr_features:
        features.append(ocr_features.get("has_text", 0.0))
        features.append(ocr_features.get("volume_ml", 0.0))
        features.append(ocr_features.get("has_ml", 0.0))
        # ìˆ«ìê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš°, ê°€ì¥ í° ìˆ«ìì™€ í‰ê·  ì¶”ê°€
        numbers = ocr_features.get("numbers", [])
        if numbers:
            features.append(float(max(numbers)))
            features.append(float(np.mean(numbers)))
        else:
            features.extend([0.0, 0.0])
    else:
        # OCR íŠ¹ì§•ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
        features.extend([0.0, 0.0, 0.0, 0.0, 0.0])
    
    # 7. ì´ë¯¸ì§€ í•´ì‹œ íŠ¹ì§• ì¶”ê°€ (perceptual hashing)
    hash_features = extract_image_hash(image)
    features.extend(hash_features)
    
    return np.array(features)


def cluster_images(
    image_dir: str,
    output_dir: str = None,
    method: str = "dbscan",
    n_clusters: int = None,
    eps: float = 0.5,
    min_samples: int = 2,
    use_ocr: bool = True,
) -> dict:
    """
    ì´ë¯¸ì§€ë“¤ì„ êµ¬ë„ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ë§í•©ë‹ˆë‹¤.
    
    Args:
        image_dir: ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        output_dir: í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì´ë¯¸ì§€ë¥¼ ë³µì‚¬í•  ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ë³µì‚¬ ì•ˆ í•¨)
        method: í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²• ("dbscan" ë˜ëŠ” "kmeans")
        n_clusters: KMeans ì‚¬ìš© ì‹œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
        eps: DBSCANì˜ eps íŒŒë¼ë¯¸í„°
        min_samples: DBSCANì˜ min_samples íŒŒë¼ë¯¸í„°
        use_ocr: OCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ íŠ¹ì§• ì¶”ì¶œ ì—¬ë¶€
    
    Returns:
        í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    image_path = Path(image_dir)
    if not image_path.exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return {}
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_files = []
    for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp', '*.JPG', '*.JPEG', '*.PNG', '*.WEBP']:
        image_files.extend(image_path.glob(ext))
    
    if not image_files:
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return {}
    
    print(f"ğŸ“¸ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
    
    # OCR ë¦¬ë” ì´ˆê¸°í™”
    ocr_reader = None
    if use_ocr and OCR_AVAILABLE:
        print("ğŸ“ OCR ë¦¬ë” ì´ˆê¸°í™” ì¤‘... (ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        try:
            ocr_reader = easyocr.Reader(['en', 'ko'], gpu=False)  # ì˜ì–´ì™€ í•œêµ­ì–´ ì§€ì›
            print("âœ… OCR ë¦¬ë” ì¤€ë¹„ ì™„ë£Œ\n")
        except Exception as e:
            print(f"âš ï¸  OCR ë¦¬ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. OCR ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.\n")
            ocr_reader = None
    elif use_ocr and not OCR_AVAILABLE:
        print("âš ï¸  OCRì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install easyocr'ì„ ì‹¤í–‰í•˜ì„¸ìš”. OCR ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.\n")
    
    # ì´ë¯¸ì§€ ë¡œë“œ ë° íŠ¹ì§• ì¶”ì¶œ
    print("ğŸ” ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
    images_data = []
    valid_files = []
    ocr_results = {}  # ë””ë²„ê¹…ìš©
    
    for img_file in sorted(image_files):
        img = load_image(img_file)
        if img is None:
            continue
        
        # OCR íŠ¹ì§• ì¶”ì¶œ
        ocr_features = None
        if ocr_reader:
            ocr_features = extract_text_from_image(img, ocr_reader)
            ocr_results[img_file.name] = ocr_features
            if ocr_features.get("volume_ml", 0) > 0:
                print(f"   ğŸ“ {img_file.name}: {ocr_features.get('volume_ml', 0)}ml ê°ì§€")
        
        features = extract_composition_features(img, ocr_features)
        if features is not None:
            images_data.append(features)
            valid_files.append(img_file)
    
    if len(images_data) < 2:
        print("âŒ í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return {}
    
    print(f"âœ… {len(images_data)}ê°œì˜ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ\n")
    
    # íŠ¹ì§• ë²¡í„° ì •ê·œí™”
    X = np.array(images_data)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # OCR ml ê°’ì— ê°€ì¤‘ì¹˜ ì ìš© (ml ê°’ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ íŠ¹ì§•ì— ë” í° ê°€ì¤‘ì¹˜)
    # ml ê°’ íŠ¹ì§•ì˜ ì¸ë±ìŠ¤ ì°¾ê¸° (OCR íŠ¹ì§•ì€ ë’¤ìª½ì— ìˆìŒ)
    # êµ¬ì¡°: [êµ¬ë„ íŠ¹ì§•ë“¤...] + [has_text, volume_ml, has_ml, max_num, avg_num] + [í•´ì‹œ 64ê°œ]
    if use_ocr and ocr_results:
        # volume_ml íŠ¹ì§•ì˜ ì¸ë±ìŠ¤ëŠ” ëŒ€ëµ êµ¬ë„ íŠ¹ì§• ê°œìˆ˜ + 1 ìœ„ì¹˜
        # ì •í™•í•œ ì¸ë±ìŠ¤ ê³„ì‚°: êµ¬ë„ íŠ¹ì§• ê°œìˆ˜ í™•ì¸
        base_features_count = len(images_data[0]) - 5 - 64  # ì „ì²´ - OCR 5ê°œ - í•´ì‹œ 64ê°œ
        volume_ml_idx = base_features_count + 1  # has_text ë‹¤ìŒì´ volume_ml
        
        # ml ê°’ì´ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ ê°€ì¤‘ì¹˜ ì ìš©
        for i, img_file in enumerate(valid_files):
            ocr_data = ocr_results.get(img_file.name, {})
            volume_ml = ocr_data.get("volume_ml", 0)
            if volume_ml > 0:
                # ml ê°’ì— í° ê°€ì¤‘ì¹˜ ì ìš© (ì •ê·œí™”ëœ ê°’ì— ì¶”ê°€)
                X_scaled[i, volume_ml_idx] *= 10.0  # ml ê°’ íŠ¹ì§•ì— 10ë°° ê°€ì¤‘ì¹˜
    
    # PCAë¡œ ì°¨ì› ì¶•ì†Œ (ì„ íƒì , ì‹œê°í™” ë° ì„±ëŠ¥ í–¥ìƒ)
    if X_scaled.shape[1] > 50:
        n_components = min(50, X_scaled.shape[0] - 1, X_scaled.shape[1])
        if n_components > 0:
            pca = PCA(n_components=n_components)
            X_scaled = pca.fit_transform(X_scaled)
            print(f"ğŸ“Š PCAë¡œ ì°¨ì› ì¶•ì†Œ: {X_scaled.shape[1]}ì°¨ì›\n")
    
    # í´ëŸ¬ìŠ¤í„°ë§
    print(f"ğŸ¯ {method.upper()} í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ ì¤‘...")
    if method.lower() == "dbscan":
        clustering = DBSCAN(eps=eps, min_samples=min_samples)
        labels = clustering.fit_predict(X_scaled)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        n_noise = list(labels).count(-1)
        print(f"âœ… {n_clusters}ê°œì˜ í´ëŸ¬ìŠ¤í„° ë°œê²¬ (ë…¸ì´ì¦ˆ: {n_noise}ê°œ)\n")
    else:  # kmeans
        if n_clusters is None:
            n_clusters = min(5, len(valid_files) // 2)
        clustering = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = clustering.fit_predict(X_scaled)
        print(f"âœ… {n_clusters}ê°œì˜ í´ëŸ¬ìŠ¤í„° ìƒì„±\n")
    
    # ê²°ê³¼ ì •ë¦¬
    clusters = defaultdict(list)
    for img_file, label in zip(valid_files, labels):
        clusters[label].append(img_file)
    
    # ê²°ê³¼ ì¶œë ¥
    print("=" * 70)
    print("í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼")
    print("=" * 70)
    for cluster_id in sorted(clusters.keys()):
        if cluster_id == -1:
            print(f"\nğŸ”¸ ë…¸ì´ì¦ˆ (í´ëŸ¬ìŠ¤í„° ì—†ìŒ): {len(clusters[cluster_id])}ê°œ")
        else:
            print(f"\nğŸ“ í´ëŸ¬ìŠ¤í„° {cluster_id}: {len(clusters[cluster_id])}ê°œ")
        for img_file in clusters[cluster_id]:
            print(f"   - {img_file.name}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"\nğŸ“‚ í´ëŸ¬ìŠ¤í„°ë³„ ì´ë¯¸ì§€ë¥¼ {output_path}ì— ë³µì‚¬ ì¤‘...")
        for cluster_id, img_files in clusters.items():
            if cluster_id == -1:
                cluster_dir = output_path / "noise"
            else:
                cluster_dir = output_path / f"cluster_{cluster_id}"
            cluster_dir.mkdir(exist_ok=True)
            
            for img_file in img_files:
                shutil.copy2(img_file, cluster_dir / img_file.name)
        
        print(f"âœ… ë³µì‚¬ ì™„ë£Œ!\n")
    
    return {
        "clusters": dict(clusters),
        "labels": labels,
        "n_clusters": n_clusters,
        "features": X_scaled,
        "ocr_results": ocr_results,
    }


def visualize_clusters(result: dict, output_path: str = "cluster_visualization.png"):
    """í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    if not result or "features" not in result:
        print("âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    features = result["features"]
    labels = result["labels"]
    
    # 2Dë¡œ ì°¨ì› ì¶•ì†Œ
    pca_2d = PCA(n_components=2)
    features_2d = pca_2d.fit_transform(features)
    
    # í”Œë¡¯
    plt.figure(figsize=(12, 8))
    unique_labels = set(labels)
    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))
    
    for k, col in zip(unique_labels, colors):
        if k == -1:
            col = 'black'  # ë…¸ì´ì¦ˆëŠ” ê²€ì€ìƒ‰
            marker = 'x'
            label = 'Noise'
        else:
            marker = 'o'
            label = f'Cluster {k}'
        
        class_member_mask = labels == k
        xy = features_2d[class_member_mask]
        plt.scatter(xy[:, 0], xy[:, 1], c=[col], marker=marker, s=50, label=label, alpha=0.6)
    
    plt.title('Image Composition Clustering Results', fontsize=14, fontweight='bold')
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š ì‹œê°í™” ê²°ê³¼ë¥¼ {output_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¹„ìŠ·í•œ êµ¬ë„ì˜ ì´ë¯¸ì§€ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•©ë‹ˆë‹¤.")
    parser.add_argument(
        "--input",
        type=str,
        default="/Users/admin/Downloads/sulwhasoo",
        help="ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="í´ëŸ¬ìŠ¤í„°ë³„ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ë³µì‚¬ ì•ˆ í•¨)",
    )
    parser.add_argument(
        "--method",
        type=str,
        choices=["dbscan", "kmeans"],
        default="dbscan",
        help="í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²• (dbscan ë˜ëŠ” kmeans)",
    )
    parser.add_argument(
        "--n-clusters",
        type=int,
        default=None,
        help="KMeans ì‚¬ìš© ì‹œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ê²°ì •)",
    )
    parser.add_argument(
        "--eps",
        type=float,
        default=0.45,
        help="DBSCANì˜ eps íŒŒë¼ë¯¸í„° (í´ëŸ¬ìŠ¤í„° ê°„ ê±°ë¦¬ ì„ê³„ê°’)",
    )
    parser.add_argument(
        "--min-samples",
        type=int,
        default=2,
        help="DBSCANì˜ min_samples íŒŒë¼ë¯¸í„° (ìµœì†Œ ìƒ˜í”Œ ìˆ˜)",
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.",
    )
    parser.add_argument(
        "--no-ocr",
        action="store_true",
        help="OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
    )
    parser.add_argument(
        "--ground-truth",
        type=str,
        default=None,
        help="ì •ë‹µ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (CSV í˜•ì‹: image_path,cluster_id) ë˜ëŠ” í‰ê°€ë¥¼ ê±´ë„ˆë›°ë ¤ë©´ ì§€ì •í•˜ì§€ ì•ŠìŒ",
    )
    parser.add_argument(
        "--generate-template",
        type=str,
        default=None,
        help="ì •ë‹µ ë°ì´í„° í…œí”Œë¦¿ CSV íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.",
    )
    
    args = parser.parse_args()
    
    # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    result = cluster_images(
        image_dir=args.input,
        output_dir=args.output,
        method=args.method,
        n_clusters=args.n_clusters,
        eps=args.eps,
        min_samples=args.min_samples,
        use_ocr=not args.no_ocr,
    )
    
    # OCR ê²°ê³¼ ì¶œë ¥
    if result and "ocr_results" in result and result["ocr_results"]:
        print("\n" + "=" * 70)
        print("OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼")
        print("=" * 70)
        has_ml = False
        for img_name, ocr_data in result["ocr_results"].items():
            volume_ml = ocr_data.get("volume_ml", 0)
            if volume_ml > 0:
                print(f"  {img_name}: {volume_ml}ml")
                has_ml = True
            elif ocr_data.get("has_text", 0) > 0:
                # í…ìŠ¤íŠ¸ëŠ” ìˆì§€ë§Œ mlì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                text = ocr_data.get("text", "")
                if text:
                    print(f"  {img_name}: í…ìŠ¤íŠ¸ ë°œê²¬ (ml ì—†ìŒ) - '{text[:50]}...'")
        if not has_ml:
            print("  (ml ë‹¨ìœ„ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)")
        print()
    
    # ì •ë‹µ ë°ì´í„° í…œí”Œë¦¿ ìƒì„±
    if args.generate_template and result:
        if not EVALUATION_AVAILABLE:
            print("âŒ í‰ê°€ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. tests/evaluate_clustering.pyë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            generate_ground_truth_template(result, args.generate_template)
    
    # ì •ë‹µ ë°ì´í„°ì™€ ë¹„êµ í‰ê°€
    if args.ground_truth and result:
        if not EVALUATION_AVAILABLE:
            print("âŒ í‰ê°€ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. tests/evaluate_clustering.pyë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            print("\n" + "=" * 70)
            print("ì •ë‹µ ë°ì´í„°ì™€ ë¹„êµ í‰ê°€")
            print("=" * 70)
            predicted_clusters = convert_cluster_result_to_list(result)
            evaluation_result = evaluate_clustering(predicted_clusters, args.ground_truth)
            print_evaluation_report(evaluation_result)
    
    # ì‹œê°í™”
    if args.visualize and result:
        visualize_clusters(result)

